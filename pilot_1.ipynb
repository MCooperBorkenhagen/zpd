{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We will tune and pilot with the 500 most frequent monosyllabic words from TASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python: base (3.11.4)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from src.learner import *\n",
    "from utilities import *\n",
    "\n",
    "\n",
    "# data\n",
    "kidwords = pd.read_csv('data/kidwords/kidwords.csv', header=None)[0].tolist()\n",
    "\n",
    "top_500 = pd.read_csv('data/top_500.csv')\n",
    "bottom_500 = pd.read_csv('data/infrequent_500.csv')\n",
    "train_word_indices = np.array([i for i, e in enumerate(kidwords) if e in top_500['word'].values])\n",
    "control_word_indices = np.array([i for i, e in enumerate(kidwords) if e in bottom_500['word'].values])\n",
    "\n",
    "XX = np.genfromtxt('data/kidwords/orth.csv', delimiter=\",\")\n",
    "YY = np.genfromtxt('data/kidwords/phon.csv', delimiter=\",\")\n",
    "\n",
    "non_zero_a = np.any(XX != 0, axis=0)\n",
    "X = XX[:, non_zero_a]\n",
    "\n",
    "non_zero_b = np.any(YY != 0, axis=0)\n",
    "Y = YY[:, non_zero_b]\n",
    "\n",
    "# configs\n",
    "with open('data/config.json', \"r\") as f:\n",
    "    cfg = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723233508.564497   39425 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723233508.585530   39425 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723233508.585656   39425 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(model, X, Y):\n",
    "    predictions = model.predict(X)\n",
    "    mse = np.mean((predictions - Y) ** 2, axis=1)\n",
    "    return mse\n",
    "\n",
    "def sample_N_to_quartiles_min(x, N, y, return_indices=True):\n",
    "\n",
    "\n",
    "    \"\"\"Calculate quartiles and min. Return the one you want.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array : an array of N values that represent the kind specified in y.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    quartiles = np.percentile(x, [25, 50, 75])\n",
    "    minimum = np.min(x)\n",
    "    maximum = np.max(x)\n",
    "    \n",
    "    # Function to find the closest N values to a given value\n",
    "    def closest_values(arr, value, N, return_indices):\n",
    "        indices = np.argsort(np.abs(arr - value))[:N]\n",
    "        return indices if return_indices else arr[indices]\n",
    "    \n",
    "    if y == \"q1\":\n",
    "        return closest_values(x, quartiles[0], N)\n",
    "    if y == \"q2\":\n",
    "        return closest_values(x, quartiles[1], N)\n",
    "    if y == \"q3\":\n",
    "        return closest_values(x, quartiles[2], N)\n",
    "    if y == \"min\":\n",
    "        return closest_values(x, minimum, N)\n",
    "    if y == \"max\":\n",
    "        return closest_values(x, maximum, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "\n",
    "for word in bottom_500['word']:\n",
    "    rowmatch = top_500[top_500['word']==word]\n",
    "    if not rowmatch.empty:\n",
    "        frequencies[word] = rowmatch['frequency'].values[0]+1\n",
    "    # all frequencies should be present, but just in case...\n",
    "    else:\n",
    "        frequencies[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_frequencies(frequencies):\n",
    "    \"\"\"\n",
    "    Scales the given word frequencies between 0 and 1.\n",
    "    \n",
    "    Parameters:\n",
    "    frequencies (dict): A dictionary where keys are words and values are their frequencies.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with scaled frequencies.\n",
    "    \"\"\"\n",
    "    max_freq = max(frequencies.values())\n",
    "    scaled_frequencies = {word: freq / max_freq for word, freq in frequencies.items()}\n",
    "    return scaled_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_frequencies = scale_frequencies(frequencies)\n",
    "frequency_weights = np.array([scaled_frequencies[word] for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representational domain #1: top 500 most frequent words\n",
    "Condition 1: maximum on distribution of MSE (i.e., the hardest condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2800])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "model = learner(X, Y, cfg['seed'], hidden=cfg['hidden_units'], optimizer=Adam(learning_rate=cfg['learning_rate']))\n",
    "\n",
    "with open('')\n",
    "\n",
    "for epoch in range(cfg['epochs']):\n",
    "    \n",
    "    mse = calculate_error(model, X[train_word_indices], Y[train_word_indices])\n",
    "    selected_indices = sample_N_to_quartiles_min(mse, cfg['N'], y = \"max\", return_indices=True)\n",
    "    \n",
    "    # Find indices of the 20 items around the median MSE\n",
    "    sorted_indices = np.argsort(np.abs(mse - median_mse))\n",
    "    selected_indices = sorted_indices[:cfg['N']]\n",
    "    \n",
    "    x = X[selected_indices]\n",
    "    y = Y[selected_indices]\n",
    "    \n",
    "    # Train the model on the selected items\n",
    "    model.fit(X[train_word_indices], Y[train_word_indices], epochs=1, verbose=1)\n",
    "\n",
    "    loss_train, accuracy_train, mse_train = model.evaluate(X[train_word_indices], Y[train_word_indices], verbose=0) \n",
    "    loss_test, accuracy_test, mse_test = model.evaluate(X[~train_word_indices], Y[~train_word_indices], verbose=0) \n",
    "\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                    hidden,\n",
    "                                    learning_rate,\n",
    "                                    batch_size,\n",
    "                                    epochs,\n",
    "                                    loss_train,\n",
    "                                    accuracy_train,\n",
    "                                    mse_train,\n",
    "                                    loss_test,\n",
    "                                    accuracy_test,\n",
    "                                    mse_test,\n",
    "                                    runtime))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
