{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We will tune and pilot with the 500 most frequent monosyllabic words from TASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from src.learner import *\n",
    "from utilities import *\n",
    "\n",
    "# data\n",
    "kidwords = pd.read_csv('data/kidwords/kidwords.csv', header=None)[0].tolist()\n",
    "\n",
    "top_500 = pd.read_csv('data/top_500.csv')\n",
    "\n",
    "words, X, Y = subset_kidwords(top_500.word.tolist(), kidwords, np.genfromtxt('data/kidwords/orth.csv', delimiter=\",\"), np.genfromtxt('data/kidwords/phon.csv', delimiter=\",\"), remove_null_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration currently training: 0.001 10 20 8\n",
      "Epoch 1/20\n",
      "287/287 [==============================] - 1s 1ms/step - loss: 0.6088 - binary_accuracy: 0.7002 - mse: 0.2105\n",
      "Epoch 2/20\n",
      "287/287 [==============================] - 0s 1ms/step - loss: 0.3472 - binary_accuracy: 0.8575 - mse: 0.1057\n",
      "Epoch 3/20\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.3186 - binary_accuracy: 0.8625 - mse: 0.0978\n",
      "Epoch 4/20\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.2975 - binary_accuracy: 0.8726 - mse: 0.0910\n",
      "Epoch 5/20\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.2780 - binary_accuracy: 0.8798 - mse: 0.0850\n",
      "Epoch 6/20\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.2629 - binary_accuracy: 0.8875 - mse: 0.0801\n",
      "Epoch 7/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.2487 - binary_accuracy: 0.8953 - mse: 0.0755\n",
      "Epoch 8/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.2345 - binary_accuracy: 0.9019 - mse: 0.0709\n",
      "Epoch 9/20\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.2206 - binary_accuracy: 0.9094 - mse: 0.0664\n",
      "Epoch 10/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.2127 - binary_accuracy: 0.9110 - mse: 0.0641\n",
      "Epoch 11/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.2042 - binary_accuracy: 0.9156 - mse: 0.0615\n",
      "Epoch 12/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1975 - binary_accuracy: 0.9186 - mse: 0.0595\n",
      "Epoch 13/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1905 - binary_accuracy: 0.9202 - mse: 0.0575\n",
      "Epoch 14/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1894 - binary_accuracy: 0.9209 - mse: 0.0572\n",
      "Epoch 15/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1828 - binary_accuracy: 0.9242 - mse: 0.0551\n",
      "Epoch 16/20\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1811 - binary_accuracy: 0.9244 - mse: 0.0547\n",
      "Epoch 17/20\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.1801 - binary_accuracy: 0.9249 - mse: 0.0544\n",
      "Epoch 18/20\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.1751 - binary_accuracy: 0.9262 - mse: 0.0529\n",
      "Epoch 19/20\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.1741 - binary_accuracy: 0.9276 - mse: 0.0526\n",
      "Epoch 20/20\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.1707 - binary_accuracy: 0.9283 - mse: 0.0516\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 8 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m                     runtime \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     39\u001b[0m                     loss_train, accuracy_train, mse_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X, Y, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m---> 41\u001b[0m                     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mloss_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43maccuracy_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mmse_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     50\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mIndexError\u001b[0m: Replacement index 8 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "seed = 323\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "with open('outputs/tune_top_500_v1.csv', 'w') as f:\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                            \"hidden_units\",\n",
    "                                            \"learning_rate\",\n",
    "                                             \"batch_size\",\n",
    "                                             \"epochs\",\n",
    "                                             \"loss_train\",\n",
    "                                             \"accuracy_train\",\n",
    "                                             \"mse_train\",\n",
    "                                             \"loss_test\",\n",
    "                                             \"accuracy_test\",\n",
    "                                             \"mse_test\",\n",
    "                                             \"time\"))\n",
    "    for learning_rate in [.001, .005, .01, .025, None]: \n",
    "        for batch_size in [10, 20, 30, 40, 50]:\n",
    "            for epochs in [20, 40, 60]:\n",
    "                for hidden in [8, 12, 16, 20]:\n",
    "                    \n",
    "                    print(\"Configuration currently training:\", learning_rate, batch_size, epochs, hidden)\n",
    "\n",
    "                    if learning_rate is not None:\n",
    "                        optimizer = Adam(learning_rate=learning_rate)\n",
    "                    if learning_rate is None:\n",
    "                        optimzer = None\n",
    "\n",
    "                    model = learner(X, Y, seed, hidden, optimizer=None)\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "\n",
    "                    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=True)\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    runtime = end_time - start_time\n",
    "\n",
    "                    loss_train, accuracy_train, mse_train = model.evaluate(X, Y, verbose=0) \n",
    "\n",
    "                    f.write(\"{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    learning_rate,\n",
    "                                                    batch_size,\n",
    "                                                    epochs,\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    runtime))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(model, X, Y):\n",
    "    predictions = model.predict(X)\n",
    "    mse = np.mean((predictions - Y) ** 2, axis=1)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "\n",
    "for word in words:\n",
    "    rowmatch = top_500[top_500['word']==word]\n",
    "    if not rowmatch.empty:\n",
    "        frequencies[word] = rowmatch['frequency'].values[0]+1\n",
    "    # all frequencies should be present, but just in case...\n",
    "    else:\n",
    "        frequencies[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_frequencies(frequencies):\n",
    "    \"\"\"\n",
    "    Scales the given word frequencies between 0 and 1.\n",
    "    \n",
    "    Parameters:\n",
    "    frequencies (dict): A dictionary where keys are words and values are their frequencies.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with scaled frequencies.\n",
    "    \"\"\"\n",
    "    max_freq = max(frequencies.values())\n",
    "    scaled_frequencies = {word: freq / max_freq for word, freq in frequencies.items()}\n",
    "    return scaled_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_frequencies = scale_frequencies(frequencies)\n",
    "frequency_weights = np.array([scaled_frequencies[word] for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09044007, 0.09044013, 0.09043867, 0.09042422, 0.0904216 ,\n",
       "       0.09042036, 0.09042026, 0.09046778, 0.09046796, 0.09040911,\n",
       "       0.09040576, 0.09040471, 0.09040409, 0.09040304, 0.09040214,\n",
       "       0.09040205, 0.09039956, 0.09039343, 0.09038391, 0.09038004,\n",
       "       0.09037878, 0.09037737, 0.09037563, 0.0903739 , 0.09037122,\n",
       "       0.09037036, 0.09036517, 0.09036351, 0.09036239, 0.09035881])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse[sorted_indices][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 406ms/step - loss: 0.6980 - binary_accuracy: 0.4867 - mse: 0.2524\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6971 - binary_accuracy: 0.5078 - mse: 0.2519\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6961 - binary_accuracy: 0.5000 - mse: 0.2514\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6951 - binary_accuracy: 0.4953 - mse: 0.2510\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6942 - binary_accuracy: 0.5172 - mse: 0.2505\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6933 - binary_accuracy: 0.4945 - mse: 0.2501\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6924 - binary_accuracy: 0.5234 - mse: 0.2496\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6915 - binary_accuracy: 0.5273 - mse: 0.2492\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6906 - binary_accuracy: 0.5305 - mse: 0.2487\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6897 - binary_accuracy: 0.5352 - mse: 0.2483\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6888 - binary_accuracy: 0.5437 - mse: 0.2478\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6879 - binary_accuracy: 0.5469 - mse: 0.2474\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6870 - binary_accuracy: 0.5469 - mse: 0.2469\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6861 - binary_accuracy: 0.5680 - mse: 0.2465\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6852 - binary_accuracy: 0.5664 - mse: 0.2461\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6843 - binary_accuracy: 0.5750 - mse: 0.2456\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6834 - binary_accuracy: 0.5797 - mse: 0.2452\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6825 - binary_accuracy: 0.5773 - mse: 0.2447\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6814 - binary_accuracy: 0.5695 - mse: 0.2442\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6805 - binary_accuracy: 0.5734 - mse: 0.2437\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6795 - binary_accuracy: 0.5914 - mse: 0.2432\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6785 - binary_accuracy: 0.5930 - mse: 0.2427\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6775 - binary_accuracy: 0.5961 - mse: 0.2422\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6765 - binary_accuracy: 0.6078 - mse: 0.2417\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6754 - binary_accuracy: 0.6125 - mse: 0.2412\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6744 - binary_accuracy: 0.6281 - mse: 0.2406\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6732 - binary_accuracy: 0.6266 - mse: 0.2401\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6721 - binary_accuracy: 0.6258 - mse: 0.2395\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6710 - binary_accuracy: 0.6391 - mse: 0.2390\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6698 - binary_accuracy: 0.6531 - mse: 0.2384\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6686 - binary_accuracy: 0.6375 - mse: 0.2378\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6673 - binary_accuracy: 0.6547 - mse: 0.2371\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6660 - binary_accuracy: 0.6461 - mse: 0.2365\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6646 - binary_accuracy: 0.6656 - mse: 0.2358\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6632 - binary_accuracy: 0.6633 - mse: 0.2351\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6618 - binary_accuracy: 0.6766 - mse: 0.2344\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6603 - binary_accuracy: 0.6648 - mse: 0.2337\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6587 - binary_accuracy: 0.6781 - mse: 0.2329\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6573 - binary_accuracy: 0.7055 - mse: 0.2322\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6556 - binary_accuracy: 0.6945 - mse: 0.2314\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6540 - binary_accuracy: 0.6906 - mse: 0.2306\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6522 - binary_accuracy: 0.7102 - mse: 0.2297\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6505 - binary_accuracy: 0.7164 - mse: 0.2288\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6487 - binary_accuracy: 0.7344 - mse: 0.2279\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6469 - binary_accuracy: 0.7414 - mse: 0.2270\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6450 - binary_accuracy: 0.7406 - mse: 0.2261\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6431 - binary_accuracy: 0.7453 - mse: 0.2252\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6411 - binary_accuracy: 0.7469 - mse: 0.2242\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6390 - binary_accuracy: 0.7273 - mse: 0.2232\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6369 - binary_accuracy: 0.7555 - mse: 0.2221\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6347 - binary_accuracy: 0.7547 - mse: 0.2211\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6326 - binary_accuracy: 0.7758 - mse: 0.2200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6303 - binary_accuracy: 0.7648 - mse: 0.2189\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6279 - binary_accuracy: 0.7625 - mse: 0.2178\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6257 - binary_accuracy: 0.7648 - mse: 0.2166\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6233 - binary_accuracy: 0.7828 - mse: 0.2154\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6208 - binary_accuracy: 0.7719 - mse: 0.2142\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6182 - binary_accuracy: 0.7820 - mse: 0.2130\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6158 - binary_accuracy: 0.8000 - mse: 0.2118\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6131 - binary_accuracy: 0.8039 - mse: 0.2105\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6104 - binary_accuracy: 0.8062 - mse: 0.2092\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6077 - binary_accuracy: 0.8102 - mse: 0.2079\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6049 - binary_accuracy: 0.8070 - mse: 0.2065\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6022 - binary_accuracy: 0.8219 - mse: 0.2051\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5993 - binary_accuracy: 0.8094 - mse: 0.2038\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5963 - binary_accuracy: 0.8102 - mse: 0.2023\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5932 - binary_accuracy: 0.8078 - mse: 0.2009\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5900 - binary_accuracy: 0.8039 - mse: 0.1995\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5871 - binary_accuracy: 0.8031 - mse: 0.1981\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5840 - binary_accuracy: 0.8094 - mse: 0.1966\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5811 - binary_accuracy: 0.8172 - mse: 0.1951\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5783 - binary_accuracy: 0.8328 - mse: 0.1937\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5751 - binary_accuracy: 0.8422 - mse: 0.1921\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5717 - binary_accuracy: 0.8383 - mse: 0.1906\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5685 - binary_accuracy: 0.8258 - mse: 0.1891\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5647 - binary_accuracy: 0.8141 - mse: 0.1876\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5616 - binary_accuracy: 0.8195 - mse: 0.1861\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5587 - binary_accuracy: 0.8375 - mse: 0.1845\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5555 - binary_accuracy: 0.8484 - mse: 0.1830\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5515 - binary_accuracy: 0.8234 - mse: 0.1815\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5481 - binary_accuracy: 0.8203 - mse: 0.1800\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5448 - binary_accuracy: 0.8148 - mse: 0.1785\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5420 - binary_accuracy: 0.8250 - mse: 0.1770\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5389 - binary_accuracy: 0.8406 - mse: 0.1755\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5353 - binary_accuracy: 0.8289 - mse: 0.1740\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5319 - binary_accuracy: 0.8344 - mse: 0.1725\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5293 - binary_accuracy: 0.8523 - mse: 0.1711\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5260 - binary_accuracy: 0.8492 - mse: 0.1696\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5226 - binary_accuracy: 0.8461 - mse: 0.1681\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5185 - binary_accuracy: 0.8445 - mse: 0.1666\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5156 - binary_accuracy: 0.8461 - mse: 0.1651\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5122 - binary_accuracy: 0.8508 - mse: 0.1636\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5084 - binary_accuracy: 0.8414 - mse: 0.1621\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5062 - binary_accuracy: 0.8555 - mse: 0.1607\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5022 - binary_accuracy: 0.8469 - mse: 0.1593\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4998 - binary_accuracy: 0.8609 - mse: 0.1578\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4960 - binary_accuracy: 0.8547 - mse: 0.1564\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4918 - binary_accuracy: 0.8469 - mse: 0.1550\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4902 - binary_accuracy: 0.8578 - mse: 0.1537\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4856 - binary_accuracy: 0.8453 - mse: 0.1524\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4824 - binary_accuracy: 0.8445 - mse: 0.1511\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4802 - binary_accuracy: 0.8508 - mse: 0.1498\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4780 - binary_accuracy: 0.8562 - mse: 0.1485\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4741 - binary_accuracy: 0.8531 - mse: 0.1472\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4711 - binary_accuracy: 0.8523 - mse: 0.1460\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4685 - binary_accuracy: 0.8539 - mse: 0.1447\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4657 - binary_accuracy: 0.8594 - mse: 0.1435\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4606 - binary_accuracy: 0.8469 - mse: 0.1423\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4581 - binary_accuracy: 0.8523 - mse: 0.1413\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4554 - binary_accuracy: 0.8453 - mse: 0.1401\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4546 - binary_accuracy: 0.8594 - mse: 0.1391\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4497 - binary_accuracy: 0.8438 - mse: 0.1380\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4472 - binary_accuracy: 0.8422 - mse: 0.1370\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4464 - binary_accuracy: 0.8516 - mse: 0.1360\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4429 - binary_accuracy: 0.8469 - mse: 0.1350\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4390 - binary_accuracy: 0.8430 - mse: 0.1340\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4361 - binary_accuracy: 0.8477 - mse: 0.1330\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4367 - binary_accuracy: 0.8633 - mse: 0.1321\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4350 - binary_accuracy: 0.8641 - mse: 0.1312\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4334 - binary_accuracy: 0.8641 - mse: 0.1303\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4290 - binary_accuracy: 0.8602 - mse: 0.1294\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4264 - binary_accuracy: 0.8617 - mse: 0.1285\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4242 - binary_accuracy: 0.8625 - mse: 0.1277\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4221 - binary_accuracy: 0.8570 - mse: 0.1268\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4190 - binary_accuracy: 0.8531 - mse: 0.1260\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4191 - binary_accuracy: 0.8609 - mse: 0.1253\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4165 - binary_accuracy: 0.8555 - mse: 0.1245\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4140 - binary_accuracy: 0.8648 - mse: 0.1237\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4091 - binary_accuracy: 0.8539 - mse: 0.1230\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4094 - binary_accuracy: 0.8586 - mse: 0.1223\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4063 - binary_accuracy: 0.8594 - mse: 0.1216\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4042 - binary_accuracy: 0.8531 - mse: 0.1210\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4050 - binary_accuracy: 0.8625 - mse: 0.1203\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4001 - binary_accuracy: 0.8555 - mse: 0.1197\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3962 - binary_accuracy: 0.8500 - mse: 0.1190\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3959 - binary_accuracy: 0.8539 - mse: 0.1185\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3913 - binary_accuracy: 0.8492 - mse: 0.1180\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3932 - binary_accuracy: 0.8586 - mse: 0.1174\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3918 - binary_accuracy: 0.8578 - mse: 0.1170\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3853 - binary_accuracy: 0.8438 - mse: 0.1165\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3895 - binary_accuracy: 0.8570 - mse: 0.1160\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3873 - binary_accuracy: 0.8570 - mse: 0.1155\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3854 - binary_accuracy: 0.8609 - mse: 0.1151\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3824 - binary_accuracy: 0.8539 - mse: 0.1147\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3811 - binary_accuracy: 0.8562 - mse: 0.1142\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3830 - binary_accuracy: 0.8656 - mse: 0.1139\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3810 - binary_accuracy: 0.8625 - mse: 0.1134\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3811 - binary_accuracy: 0.8609 - mse: 0.1130\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3769 - binary_accuracy: 0.8555 - mse: 0.1125\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3755 - binary_accuracy: 0.8531 - mse: 0.1121\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3750 - binary_accuracy: 0.8555 - mse: 0.1118\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3715 - binary_accuracy: 0.8469 - mse: 0.1114\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3701 - binary_accuracy: 0.8562 - mse: 0.1111\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3721 - binary_accuracy: 0.8578 - mse: 0.1107\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3683 - binary_accuracy: 0.8508 - mse: 0.1104\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3640 - binary_accuracy: 0.8477 - mse: 0.1100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3678 - binary_accuracy: 0.8477 - mse: 0.1096\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3652 - binary_accuracy: 0.8531 - mse: 0.1093\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3660 - binary_accuracy: 0.8570 - mse: 0.1089\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8531 - mse: 0.1086\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3641 - binary_accuracy: 0.8680 - mse: 0.1083\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3627 - binary_accuracy: 0.8594 - mse: 0.1081\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3612 - binary_accuracy: 0.8562 - mse: 0.1079\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3558 - binary_accuracy: 0.8516 - mse: 0.1077\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3563 - binary_accuracy: 0.8602 - mse: 0.1074\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3586 - binary_accuracy: 0.8648 - mse: 0.1072\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3572 - binary_accuracy: 0.8602 - mse: 0.1071\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3604 - binary_accuracy: 0.8703 - mse: 0.1068\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3565 - binary_accuracy: 0.8664 - mse: 0.1065\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3540 - binary_accuracy: 0.8648 - mse: 0.1063\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3527 - binary_accuracy: 0.8602 - mse: 0.1061\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3519 - binary_accuracy: 0.8633 - mse: 0.1061\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3490 - binary_accuracy: 0.8578 - mse: 0.1059\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3497 - binary_accuracy: 0.8594 - mse: 0.1056\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3525 - binary_accuracy: 0.8633 - mse: 0.1055\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3532 - binary_accuracy: 0.8656 - mse: 0.1053\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3503 - binary_accuracy: 0.8648 - mse: 0.1051\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3497 - binary_accuracy: 0.8641 - mse: 0.1049\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3494 - binary_accuracy: 0.8633 - mse: 0.1048\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3476 - binary_accuracy: 0.8602 - mse: 0.1047\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3469 - binary_accuracy: 0.8609 - mse: 0.1045\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3461 - binary_accuracy: 0.8586 - mse: 0.1043\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3425 - binary_accuracy: 0.8594 - mse: 0.1042\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3440 - binary_accuracy: 0.8664 - mse: 0.1041\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3433 - binary_accuracy: 0.8672 - mse: 0.1039\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3444 - binary_accuracy: 0.8672 - mse: 0.1038\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3434 - binary_accuracy: 0.8641 - mse: 0.1037\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3419 - binary_accuracy: 0.8641 - mse: 0.1036\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3390 - binary_accuracy: 0.8625 - mse: 0.1035\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3402 - binary_accuracy: 0.8664 - mse: 0.1034\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3402 - binary_accuracy: 0.8664 - mse: 0.1033\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3399 - binary_accuracy: 0.8625 - mse: 0.1032\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3382 - binary_accuracy: 0.8602 - mse: 0.1032\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3362 - binary_accuracy: 0.8586 - mse: 0.1030\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_accuracy: 0.8633 - mse: 0.1029\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3385 - binary_accuracy: 0.8664 - mse: 0.1028\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3394 - binary_accuracy: 0.8656 - mse: 0.1027\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3379 - binary_accuracy: 0.8648 - mse: 0.1026\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3383 - binary_accuracy: 0.8672 - mse: 0.1024\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3365 - binary_accuracy: 0.8625 - mse: 0.1024\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3345 - binary_accuracy: 0.8586 - mse: 0.1023\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3345 - binary_accuracy: 0.8578 - mse: 0.1022\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3338 - binary_accuracy: 0.8594 - mse: 0.1021\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3353 - binary_accuracy: 0.8570 - mse: 0.1021\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3396 - binary_accuracy: 0.8664 - mse: 0.1020\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3395 - binary_accuracy: 0.8750 - mse: 0.1019\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3399 - binary_accuracy: 0.8695 - mse: 0.1018\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3367 - binary_accuracy: 0.8656 - mse: 0.1017\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3358 - binary_accuracy: 0.8664 - mse: 0.1017\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3358 - binary_accuracy: 0.8695 - mse: 0.1016\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3333 - binary_accuracy: 0.8672 - mse: 0.1016\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3322 - binary_accuracy: 0.8625 - mse: 0.1014\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3321 - binary_accuracy: 0.8672 - mse: 0.1014\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3330 - binary_accuracy: 0.8680 - mse: 0.1013\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3309 - binary_accuracy: 0.8617 - mse: 0.1013\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3285 - binary_accuracy: 0.8602 - mse: 0.1012\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3303 - binary_accuracy: 0.8602 - mse: 0.1011\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3309 - binary_accuracy: 0.8633 - mse: 0.1011\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3298 - binary_accuracy: 0.8609 - mse: 0.1010\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3320 - binary_accuracy: 0.8648 - mse: 0.1010\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3315 - binary_accuracy: 0.8656 - mse: 0.1009\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3270 - binary_accuracy: 0.8609 - mse: 0.1009\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3322 - binary_accuracy: 0.8703 - mse: 0.1008\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3279 - binary_accuracy: 0.8633 - mse: 0.1007\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3304 - binary_accuracy: 0.8617 - mse: 0.1007\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3287 - binary_accuracy: 0.8602 - mse: 0.1006\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3254 - binary_accuracy: 0.8625 - mse: 0.1006\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3301 - binary_accuracy: 0.8633 - mse: 0.1005\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3326 - binary_accuracy: 0.8641 - mse: 0.1005\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3279 - binary_accuracy: 0.8578 - mse: 0.1004\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3292 - binary_accuracy: 0.8641 - mse: 0.1004\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3264 - binary_accuracy: 0.8594 - mse: 0.1003\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3239 - binary_accuracy: 0.8664 - mse: 0.1002\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3256 - binary_accuracy: 0.8617 - mse: 0.1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3280 - binary_accuracy: 0.8633 - mse: 0.1001\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3284 - binary_accuracy: 0.8648 - mse: 0.1001\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3291 - binary_accuracy: 0.8672 - mse: 0.1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3220 - binary_accuracy: 0.8539 - mse: 0.1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3234 - binary_accuracy: 0.8562 - mse: 0.0999\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3278 - binary_accuracy: 0.8680 - mse: 0.0999\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3247 - binary_accuracy: 0.8617 - mse: 0.0998\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3269 - binary_accuracy: 0.8625 - mse: 0.0997\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3246 - binary_accuracy: 0.8609 - mse: 0.0997\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3286 - binary_accuracy: 0.8680 - mse: 0.0996\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3266 - binary_accuracy: 0.8727 - mse: 0.0996\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3221 - binary_accuracy: 0.8633 - mse: 0.0996\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3207 - binary_accuracy: 0.8508 - mse: 0.0995\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3265 - binary_accuracy: 0.8641 - mse: 0.0995\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3246 - binary_accuracy: 0.8633 - mse: 0.0994\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3216 - binary_accuracy: 0.8641 - mse: 0.0994\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3249 - binary_accuracy: 0.8625 - mse: 0.0993\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3247 - binary_accuracy: 0.8641 - mse: 0.0993\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3204 - binary_accuracy: 0.8586 - mse: 0.0992\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3224 - binary_accuracy: 0.8578 - mse: 0.0992\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3214 - binary_accuracy: 0.8594 - mse: 0.0992\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3221 - binary_accuracy: 0.8719 - mse: 0.0991\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3254 - binary_accuracy: 0.8641 - mse: 0.0991\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3245 - binary_accuracy: 0.8594 - mse: 0.0991\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3220 - binary_accuracy: 0.8609 - mse: 0.0990\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3248 - binary_accuracy: 0.8695 - mse: 0.0990\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3228 - binary_accuracy: 0.8680 - mse: 0.0989\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3206 - binary_accuracy: 0.8617 - mse: 0.0989\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3174 - binary_accuracy: 0.8586 - mse: 0.0988\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3202 - binary_accuracy: 0.8625 - mse: 0.0988\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3235 - binary_accuracy: 0.8727 - mse: 0.0988\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3213 - binary_accuracy: 0.8602 - mse: 0.0987\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3232 - binary_accuracy: 0.8586 - mse: 0.0987\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3210 - binary_accuracy: 0.8680 - mse: 0.0986\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3174 - binary_accuracy: 0.8641 - mse: 0.0986\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3220 - binary_accuracy: 0.8703 - mse: 0.0986\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3221 - binary_accuracy: 0.8664 - mse: 0.0985\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3159 - binary_accuracy: 0.8648 - mse: 0.0985\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3201 - binary_accuracy: 0.8609 - mse: 0.0985\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3213 - binary_accuracy: 0.8625 - mse: 0.0984\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3185 - binary_accuracy: 0.8633 - mse: 0.0984\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3167 - binary_accuracy: 0.8672 - mse: 0.0983\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3186 - binary_accuracy: 0.8633 - mse: 0.0983\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3217 - binary_accuracy: 0.8680 - mse: 0.0983\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3202 - binary_accuracy: 0.8594 - mse: 0.0982\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3181 - binary_accuracy: 0.8531 - mse: 0.0982\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3193 - binary_accuracy: 0.8641 - mse: 0.0981\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3170 - binary_accuracy: 0.8719 - mse: 0.0981\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3217 - binary_accuracy: 0.8703 - mse: 0.0981\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3197 - binary_accuracy: 0.8656 - mse: 0.0980\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3180 - binary_accuracy: 0.8594 - mse: 0.0980\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3171 - binary_accuracy: 0.8617 - mse: 0.0980\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3134 - binary_accuracy: 0.8625 - mse: 0.0979\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3190 - binary_accuracy: 0.8672 - mse: 0.0979\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3155 - binary_accuracy: 0.8609 - mse: 0.0979\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3131 - binary_accuracy: 0.8625 - mse: 0.0978\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3193 - binary_accuracy: 0.8711 - mse: 0.0978\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3172 - binary_accuracy: 0.8648 - mse: 0.0978\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3163 - binary_accuracy: 0.8625 - mse: 0.0977\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3156 - binary_accuracy: 0.8633 - mse: 0.0977\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3139 - binary_accuracy: 0.8641 - mse: 0.0977\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3211 - binary_accuracy: 0.8703 - mse: 0.0976\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3199 - binary_accuracy: 0.8594 - mse: 0.0976\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3155 - binary_accuracy: 0.8687 - mse: 0.0975\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3115 - binary_accuracy: 0.8625 - mse: 0.0975\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3140 - binary_accuracy: 0.8656 - mse: 0.0975\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3128 - binary_accuracy: 0.8586 - mse: 0.0974\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3146 - binary_accuracy: 0.8625 - mse: 0.0974\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3227 - binary_accuracy: 0.8742 - mse: 0.0974\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3211 - binary_accuracy: 0.8687 - mse: 0.0973\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3138 - binary_accuracy: 0.8547 - mse: 0.0973\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3145 - binary_accuracy: 0.8664 - mse: 0.0973\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3171 - binary_accuracy: 0.8719 - mse: 0.0972\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3104 - binary_accuracy: 0.8625 - mse: 0.0972\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3112 - binary_accuracy: 0.8672 - mse: 0.0972\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3111 - binary_accuracy: 0.8602 - mse: 0.0971\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3135 - binary_accuracy: 0.8625 - mse: 0.0971\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3158 - binary_accuracy: 0.8773 - mse: 0.0971\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3138 - binary_accuracy: 0.8695 - mse: 0.0970\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3140 - binary_accuracy: 0.8633 - mse: 0.0970\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3151 - binary_accuracy: 0.8586 - mse: 0.0969\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3106 - binary_accuracy: 0.8641 - mse: 0.0969\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3110 - binary_accuracy: 0.8664 - mse: 0.0969\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3149 - binary_accuracy: 0.8695 - mse: 0.0968\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3181 - binary_accuracy: 0.8719 - mse: 0.0968\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3117 - binary_accuracy: 0.8680 - mse: 0.0968\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3118 - binary_accuracy: 0.8609 - mse: 0.0967\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3134 - binary_accuracy: 0.8695 - mse: 0.0967\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3136 - binary_accuracy: 0.8680 - mse: 0.0967\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3118 - binary_accuracy: 0.8617 - mse: 0.0966\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3113 - binary_accuracy: 0.8766 - mse: 0.0966\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3134 - binary_accuracy: 0.8617 - mse: 0.0966\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3071 - binary_accuracy: 0.8602 - mse: 0.0965\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3141 - binary_accuracy: 0.8750 - mse: 0.0965\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3098 - binary_accuracy: 0.8711 - mse: 0.0965\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3125 - binary_accuracy: 0.8656 - mse: 0.0964\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3155 - binary_accuracy: 0.8719 - mse: 0.0964\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3104 - binary_accuracy: 0.8672 - mse: 0.0963\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3115 - binary_accuracy: 0.8594 - mse: 0.0963\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3094 - binary_accuracy: 0.8609 - mse: 0.0963\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3095 - binary_accuracy: 0.8672 - mse: 0.0962\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3126 - binary_accuracy: 0.8734 - mse: 0.0962\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3123 - binary_accuracy: 0.8742 - mse: 0.0962\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3108 - binary_accuracy: 0.8672 - mse: 0.0961\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3082 - binary_accuracy: 0.8664 - mse: 0.0961\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3128 - binary_accuracy: 0.8680 - mse: 0.0960\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3075 - binary_accuracy: 0.8680 - mse: 0.0960\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3070 - binary_accuracy: 0.8656 - mse: 0.0960\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3142 - binary_accuracy: 0.8672 - mse: 0.0959\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3138 - binary_accuracy: 0.8734 - mse: 0.0959\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3101 - binary_accuracy: 0.8703 - mse: 0.0959\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3100 - binary_accuracy: 0.8648 - mse: 0.0958\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3087 - binary_accuracy: 0.8602 - mse: 0.0958\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3088 - binary_accuracy: 0.8695 - mse: 0.0957\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3110 - binary_accuracy: 0.8703 - mse: 0.0957\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3073 - binary_accuracy: 0.8641 - mse: 0.0957\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3066 - binary_accuracy: 0.8664 - mse: 0.0956\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3116 - binary_accuracy: 0.8664 - mse: 0.0956\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3082 - binary_accuracy: 0.8781 - mse: 0.0956\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3118 - binary_accuracy: 0.8664 - mse: 0.0955\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3085 - binary_accuracy: 0.8648 - mse: 0.0955\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3100 - binary_accuracy: 0.8641 - mse: 0.0954\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3097 - binary_accuracy: 0.8758 - mse: 0.0954\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3129 - binary_accuracy: 0.8766 - mse: 0.0954\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3056 - binary_accuracy: 0.8617 - mse: 0.0953\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3025 - binary_accuracy: 0.8602 - mse: 0.0953\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3026 - binary_accuracy: 0.8672 - mse: 0.0953\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3074 - binary_accuracy: 0.8695 - mse: 0.0952\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3142 - binary_accuracy: 0.8766 - mse: 0.0952\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3115 - binary_accuracy: 0.8672 - mse: 0.0952\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3049 - binary_accuracy: 0.8719 - mse: 0.0951\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3065 - binary_accuracy: 0.8633 - mse: 0.0951\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3041 - binary_accuracy: 0.8664 - mse: 0.0951\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3074 - binary_accuracy: 0.8711 - mse: 0.0950\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3103 - binary_accuracy: 0.8742 - mse: 0.0950\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3118 - binary_accuracy: 0.8703 - mse: 0.0950\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3109 - binary_accuracy: 0.8727 - mse: 0.0949\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3050 - binary_accuracy: 0.8641 - mse: 0.0949\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3053 - binary_accuracy: 0.8609 - mse: 0.0948\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3086 - binary_accuracy: 0.8758 - mse: 0.0948\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3024 - binary_accuracy: 0.8695 - mse: 0.0948\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3027 - binary_accuracy: 0.8609 - mse: 0.0947\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3045 - binary_accuracy: 0.8695 - mse: 0.0947\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3148 - binary_accuracy: 0.8773 - mse: 0.0946\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3103 - binary_accuracy: 0.8781 - mse: 0.0946\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3047 - binary_accuracy: 0.8664 - mse: 0.0946\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3022 - binary_accuracy: 0.8719 - mse: 0.0945\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3057 - binary_accuracy: 0.8641 - mse: 0.0945\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3089 - binary_accuracy: 0.8734 - mse: 0.0945\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3018 - binary_accuracy: 0.8680 - mse: 0.0944\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3032 - binary_accuracy: 0.8719 - mse: 0.0944\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3017 - binary_accuracy: 0.8648 - mse: 0.0944\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3043 - binary_accuracy: 0.8687 - mse: 0.0943\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3055 - binary_accuracy: 0.8711 - mse: 0.0943\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3077 - binary_accuracy: 0.8750 - mse: 0.0942\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3009 - binary_accuracy: 0.8625 - mse: 0.0942\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3042 - binary_accuracy: 0.8711 - mse: 0.0942\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3020 - binary_accuracy: 0.8711 - mse: 0.0942\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3029 - binary_accuracy: 0.8695 - mse: 0.0941\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3030 - binary_accuracy: 0.8742 - mse: 0.0941\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3063 - binary_accuracy: 0.8773 - mse: 0.0940\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3001 - binary_accuracy: 0.8648 - mse: 0.0940\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3011 - binary_accuracy: 0.8687 - mse: 0.0940\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3047 - binary_accuracy: 0.8711 - mse: 0.0939\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3107 - binary_accuracy: 0.8758 - mse: 0.0939\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3063 - binary_accuracy: 0.8781 - mse: 0.0939\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3042 - binary_accuracy: 0.8641 - mse: 0.0938\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3020 - binary_accuracy: 0.8594 - mse: 0.0938\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3052 - binary_accuracy: 0.8734 - mse: 0.0938\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3020 - binary_accuracy: 0.8820 - mse: 0.0937\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3000 - binary_accuracy: 0.8656 - mse: 0.0937\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2993 - binary_accuracy: 0.8664 - mse: 0.0937\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2961 - binary_accuracy: 0.8664 - mse: 0.0936\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3064 - binary_accuracy: 0.8742 - mse: 0.0936\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3064 - binary_accuracy: 0.8719 - mse: 0.0936\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3013 - binary_accuracy: 0.8664 - mse: 0.0935\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3022 - binary_accuracy: 0.8781 - mse: 0.0935\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2954 - binary_accuracy: 0.8734 - mse: 0.0935\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3015 - binary_accuracy: 0.8641 - mse: 0.0934\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3062 - binary_accuracy: 0.8805 - mse: 0.0934\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3006 - binary_accuracy: 0.8703 - mse: 0.0934\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3020 - binary_accuracy: 0.8766 - mse: 0.0933\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2984 - binary_accuracy: 0.8703 - mse: 0.0933\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2974 - binary_accuracy: 0.8656 - mse: 0.0933\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3036 - binary_accuracy: 0.8727 - mse: 0.0932\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3043 - binary_accuracy: 0.8766 - mse: 0.0932\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3041 - binary_accuracy: 0.8766 - mse: 0.0931\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3008 - binary_accuracy: 0.8711 - mse: 0.0931\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2970 - binary_accuracy: 0.8672 - mse: 0.0931\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3005 - binary_accuracy: 0.8695 - mse: 0.0930\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2998 - binary_accuracy: 0.8734 - mse: 0.0930\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2983 - binary_accuracy: 0.8758 - mse: 0.0930\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3015 - binary_accuracy: 0.8695 - mse: 0.0930\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2985 - binary_accuracy: 0.8586 - mse: 0.0929\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2970 - binary_accuracy: 0.8680 - mse: 0.0929\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3016 - binary_accuracy: 0.8828 - mse: 0.0929\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3025 - binary_accuracy: 0.8789 - mse: 0.0928\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3020 - binary_accuracy: 0.8664 - mse: 0.0928\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2981 - binary_accuracy: 0.8664 - mse: 0.0928\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3071 - binary_accuracy: 0.8813 - mse: 0.0927\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2990 - binary_accuracy: 0.8734 - mse: 0.0927\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2949 - binary_accuracy: 0.8641 - mse: 0.0926\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2972 - binary_accuracy: 0.8695 - mse: 0.0926\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2987 - binary_accuracy: 0.8641 - mse: 0.0926\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3022 - binary_accuracy: 0.8789 - mse: 0.0925\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2974 - binary_accuracy: 0.8758 - mse: 0.0925\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3038 - binary_accuracy: 0.8758 - mse: 0.0925\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2983 - binary_accuracy: 0.8773 - mse: 0.0924\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2958 - binary_accuracy: 0.8758 - mse: 0.0924\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2986 - binary_accuracy: 0.8664 - mse: 0.0924\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2951 - binary_accuracy: 0.8687 - mse: 0.0923\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2947 - binary_accuracy: 0.8711 - mse: 0.0923\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2991 - binary_accuracy: 0.8758 - mse: 0.0923\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2985 - binary_accuracy: 0.8711 - mse: 0.0922\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2958 - binary_accuracy: 0.8734 - mse: 0.0922\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2997 - binary_accuracy: 0.8711 - mse: 0.0922\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2944 - binary_accuracy: 0.8656 - mse: 0.0921\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2974 - binary_accuracy: 0.8781 - mse: 0.0921\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2974 - binary_accuracy: 0.8766 - mse: 0.0921\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2995 - binary_accuracy: 0.8758 - mse: 0.0920\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2980 - binary_accuracy: 0.8727 - mse: 0.0920\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2989 - binary_accuracy: 0.8742 - mse: 0.0920\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2940 - binary_accuracy: 0.8687 - mse: 0.0919\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2884 - binary_accuracy: 0.8617 - mse: 0.0919\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2986 - binary_accuracy: 0.8836 - mse: 0.0919\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2980 - binary_accuracy: 0.8727 - mse: 0.0918\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2969 - binary_accuracy: 0.8664 - mse: 0.0918\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2976 - binary_accuracy: 0.8719 - mse: 0.0917\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2988 - binary_accuracy: 0.8789 - mse: 0.0917\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2975 - binary_accuracy: 0.8672 - mse: 0.0917\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2981 - binary_accuracy: 0.8773 - mse: 0.0916\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2924 - binary_accuracy: 0.8758 - mse: 0.0916\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2975 - binary_accuracy: 0.8758 - mse: 0.0916\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2967 - binary_accuracy: 0.8766 - mse: 0.0915\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2904 - binary_accuracy: 0.8648 - mse: 0.0915\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3003 - binary_accuracy: 0.8820 - mse: 0.0915\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2975 - binary_accuracy: 0.8734 - mse: 0.0914\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2932 - binary_accuracy: 0.8703 - mse: 0.0914\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2928 - binary_accuracy: 0.8719 - mse: 0.0914\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2942 - binary_accuracy: 0.8734 - mse: 0.0913\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2928 - binary_accuracy: 0.8711 - mse: 0.0913\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2909 - binary_accuracy: 0.8648 - mse: 0.0912\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2914 - binary_accuracy: 0.8719 - mse: 0.0912\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2944 - binary_accuracy: 0.8789 - mse: 0.0912\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2934 - binary_accuracy: 0.8750 - mse: 0.0911\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2959 - binary_accuracy: 0.8703 - mse: 0.0911\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2968 - binary_accuracy: 0.8750 - mse: 0.0911\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2907 - binary_accuracy: 0.8711 - mse: 0.0911\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2998 - binary_accuracy: 0.8805 - mse: 0.0910\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2954 - binary_accuracy: 0.8703 - mse: 0.0910\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2920 - binary_accuracy: 0.8734 - mse: 0.0909\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2892 - binary_accuracy: 0.8656 - mse: 0.0909\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2942 - binary_accuracy: 0.8766 - mse: 0.0909\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2942 - binary_accuracy: 0.8742 - mse: 0.0908\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2876 - binary_accuracy: 0.8648 - mse: 0.0908\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2903 - binary_accuracy: 0.8727 - mse: 0.0908\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2935 - binary_accuracy: 0.8789 - mse: 0.0907\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3011 - binary_accuracy: 0.8813 - mse: 0.0907\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2939 - binary_accuracy: 0.8742 - mse: 0.0906\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2904 - binary_accuracy: 0.8750 - mse: 0.0906\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2905 - binary_accuracy: 0.8727 - mse: 0.0906\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2913 - binary_accuracy: 0.8656 - mse: 0.0905\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2934 - binary_accuracy: 0.8711 - mse: 0.0905\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2957 - binary_accuracy: 0.8836 - mse: 0.0905\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2957 - binary_accuracy: 0.8828 - mse: 0.0904\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2883 - binary_accuracy: 0.8664 - mse: 0.0904\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 500  # Set the number of epochs\n",
    "N = 20  # Number of items to select\n",
    "seed = 349\n",
    "model = learner(X, Y, seed, hidden=15, optimizer=Adam(learning_rate=.001))\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    mse = calculate_error(model, X, Y)\n",
    "    median_mse = np.median(mse)\n",
    "    \n",
    "    # Find indices of the 20 items around the median MSE\n",
    "    sorted_indices = np.argsort(np.abs(mse - median_mse))\n",
    "    selected_indices = sorted_indices[:N]\n",
    "    \n",
    "    x = X[selected_indices]\n",
    "    y = Y[selected_indices]\n",
    "    \n",
    "    # Train the model on the selected items\n",
    "    model.fit(x, y, epochs=1, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
