{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python: base (3.11.4)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "from src.learner import *\n",
    "from utilities import *\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "\n",
    "    def __init__(self, accuracy_criteria=1.0, accuracy_metric_name='binary_accuracy'):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.accuracy_criteria = accuracy_criteria\n",
    "        self.accuracy_metric_name = accuracy_metric_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        accuracy = logs.get(self.accuracy_metric_name)\n",
    "        if accuracy is not None:\n",
    "            print(f\"Epoch {epoch+1}: Accuracy = {accuracy}\")\n",
    "            if accuracy >= self.accuracy_criteria:\n",
    "                print(f\"Reached {self.accuracy_criteria * 100}% accuracy, stopping training!\")\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}: Accuracy not found in logs.\")\n",
    "\n",
    "\n",
    "# data\n",
    "kidwords = pd.read_csv('data/kidwords/kidwords.csv', header=None)[0].tolist()\n",
    "kidwords_frequencies_from_tasa = pd.read_csv('data/kidword_frequencies_from_tasa.csv') # some words from kidwords aren't represented so we have to impute 0\n",
    "\n",
    "\n",
    "top_500 = pd.read_csv('data/top_500.csv')\n",
    "bottom_500 = pd.read_csv('data/infrequent_500.csv')\n",
    "train_word_indices = np.array([i for i, e in enumerate(kidwords) if e in top_500['word'].values])\n",
    "\n",
    "control_word_indices = np.array([i for i, e in enumerate(kidwords) if e in bottom_500['word'].values])\n",
    "\n",
    "XX = np.genfromtxt('data/kidwords/orth.csv', delimiter=\",\")\n",
    "YY = np.genfromtxt('data/kidwords/phon.csv', delimiter=\",\")\n",
    "\n",
    "non_zero_a = np.any(XX != 0, axis=0)\n",
    "X = XX[:, non_zero_a]\n",
    "\n",
    "non_zero_b = np.any(YY != 0, axis=0)\n",
    "Y = YY[:, non_zero_b]\n",
    "\n",
    "# configs\n",
    "with open('data/config.json', \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) # may not work depending on kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_nearest_neighbors(x, indices, N):\n",
    "    \n",
    "    \"\"\"Find the indices of the nearest N neighbors for each element along axis 0 (rows) of the similarity matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x (numpy.ndarray): A 2D array, the similarity matrix.\n",
    "    \n",
    "    N (int): The number of nearest neighbors you'd like the indices of.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray: A 2D array. Each row contains the indices of the nearest N neighbors for the corresponding element provided by the original indices.\n",
    "    \"\"\"\n",
    "    # Ensure the similarity matrix is a numpy array\n",
    "    similarity_matrix = np.array(x)\n",
    "    \n",
    "    # Get the indices of the sorted similarities in descending order\n",
    "    sorted_indices = np.argsort(-similarity_matrix, axis=1)\n",
    "    \n",
    "    # Select the top N indices for each row\n",
    "    nearest_neighbors_indices = sorted_indices[:, 1:N + 1]  # Exclude the first index (self-similarity)\n",
    "    \n",
    "    return np.array(indices)[nearest_neighbors_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner(X, Y, cfg['seed'], cfg['hidden_units'], optimizer='adam')\n",
    "model.fit(X[train_word_indices], Y[train_word_indices], epochs=cfg['epochs'], batch_size=cfg['batch_size'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that outputs the hidden layer activations\n",
    "\n",
    "\n",
    "hidden_layer_model = Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "\n",
    "hidden_activations = hidden_layer_model.predict(X)\n",
    "\n",
    "# Convert the activations to a DataFrame\n",
    "df = pd.DataFrame(hidden_activations)\n",
    "\n",
    "df.to_csv('outputs/pilot_1_hidden_unit_activations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity matrix\n",
    "similarities = cosine_similarity(hidden_activations)\n",
    "\n",
    "np.savetxt('outputs/pilot_1_hidden_unit_activation_similarities.csv', similarities, delimiter = \",\", fmt = '%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
